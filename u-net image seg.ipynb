{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Dropout, Conv2DTranspose, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Dropout, Conv2DTranspose, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nstrategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n\n# load the datasets\nimg_dir = '/kaggle/input/ussimandsegm/abdominal_US/abdominal_US/AUS/images/train'\nmask_dir = '/kaggle/input/ussimandsegm/abdominal_US/abdominal_US/AUS/annotations/train'\n\n# Load and preprocess the training images.\nimg_names = os.listdir(img_dir)\nimgs = [Image.open(os.path.join(img_dir, img_name)) for img_name in img_names]\nX = np.array([np.array(img.resize((464, 464))) for img in imgs])\nX = X / 255.0  # Normalize the images to [0, 1] range.\n\n # Define a mapping from RGB values to class labels.\ncolors_to_labels = {\n        (255, 255, 0): 0,  # Yellow\n        (255, 0, 255): 1,  # Red\n        (100, 0, 100): 2,  # Darker red\n        (0, 255, 0): 3  # Green\n    }\n\n# Load, preprocess, and encode the masks.\nmask_names = os.listdir(mask_dir)\nmasks = [Image.open(os.path.join(mask_dir, mask_name)) for mask_name in mask_names]\nmasks = [mask.resize((464, 464)) for mask in masks] \nY = np.empty((len(masks), 464, 464, len(colors_to_labels)))\n\nfor i, mask in enumerate(masks):\n    mask_array = np.array(mask)\n    for j, (color, label) in enumerate(colors_to_labels.items()):\n        Y[i, :, :, j] = np.all(mask_array == np.array(color).reshape(1, 1, 3), axis=2)\n\n# Split the data into a training set and a validation set.\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n\n# Define the U-Net model.\ninputs = Input((464, 464, 3))\nconv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)\nconv1 = BatchNormalization()(conv1)\nconv1 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\nconv1 = BatchNormalization()(conv1)\ndrop1 = Dropout(0.5)(conv1)\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\nconv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)\nconv2 = BatchNormalization()(conv2)\nconv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)\nconv2 = BatchNormalization()(conv2)\ndrop2 = Dropout(0.5)(conv2)\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\nconv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)\nconv3 = BatchNormalization()(conv3)\nconv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)\nconv3 = BatchNormalization()(conv3)\ndrop3 = Dropout(0.5)(conv3)\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\nconv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)\nconv4 = BatchNormalization()(conv4)\nconv4 = Conv2D(256, 3, activation='relu', padding='same')(conv4)\nconv4 = BatchNormalization()(conv4)\ndrop4 = Dropout(0.5)(conv4)\npool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n    \nconv5 = Conv2D(512, 3, activation='relu', padding='same')(pool4)\nconv5 = BatchNormalization()(conv5)\nconv5 = Conv2D(512, 3, activation='relu', padding='same')(conv5)\nconv5 = BatchNormalization()(conv5)\ndrop5 = Dropout(0.5)(conv5)\n\nup6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(drop5)\nmerge6 = concatenate([drop4, up6], axis=3)\nconv6 = Conv2D(256, 3, activation='relu', padding='same')(merge6)\nconv6 = BatchNormalization()(conv6)\nconv6 = Conv2D(256, 3, activation='relu', padding='same')(conv6)\nconv6 = BatchNormalization()(conv6)\ndrop6= Dropout(0.5)(conv6)\n\nup7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(drop6)\nmerge7 = concatenate([conv3, up7], axis=3)\nconv7 = Conv2D(128, 3, activation='relu', padding='same')(merge7)\nconv7 = BatchNormalization()(conv7)\nconv7 = Conv2D(128, 3, activation='relu', padding='same')(conv7)\nconv7 = BatchNormalization()(conv7)\ndrop7= Dropout(0.5)(conv7)\n\nup8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(drop7)\nmerge8 = concatenate([conv2, up8], axis=3)\nconv8 = Conv2D(64, 3, activation='relu', padding='same')(merge8)\nconv8 = BatchNormalization()(conv8)\nconv8 = Conv2D(64, 3, activation='relu', padding='same')(conv8)\nconv8 = BatchNormalization()(conv8)\ndrop8= Dropout(0.5)(conv8)\n\nup9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(drop8)\nmerge9 = concatenate([conv1, up9], axis=3)\nconv9 = Conv2D(32, 3, activation='relu', padding='same')(merge9)\nconv9 = BatchNormalization()(conv9)\nconv9 = Conv2D(32, 3, activation='relu', padding='same')(conv9)\nconv9 = BatchNormalization()(conv9)\n\nconv10 = Conv2D(len(colors_to_labels), 1, activation='softmax')(conv9)\n    \n    \nmodel = Model(inputs, conv10)\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy')\n\n\n# Train the model.\nresults = model.fit(X_train, Y_train, batch_size=4, epochs=15, validation_data=(X_val, Y_val))","metadata":{"execution":{"iopub.status.busy":"2023-06-17T21:44:46.764090Z","iopub.execute_input":"2023-06-17T21:44:46.764464Z","iopub.status.idle":"2023-06-17T23:48:48.727037Z","shell.execute_reply.started":"2023-06-17T21:44:46.764434Z","shell.execute_reply":"2023-06-17T23:48:48.725925Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"D0617 21:45:18.704755936      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0617 21:45:18.704781240      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0617 21:45:18.704784612      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0617 21:45:18.704787100      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0617 21:45:18.704789076      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0617 21:45:18.704791472      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0617 21:45:18.704793777      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0617 21:45:18.704795709      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0617 21:45:18.704797708      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0617 21:45:18.704799975      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0617 21:45:18.704801913      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0617 21:45:18.704805174      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0617 21:45:18.704807428      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0617 21:45:18.704809489      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0617 21:45:18.704974154      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 62\nD0617 21:45:18.704991535      14 ev_posix.cc:144]                      Using polling engine: epoll1\nD0617 21:45:18.705010362      14 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0617 21:45:18.714361992      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0617 21:45:18.714373501      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0617 21:45:18.714377468      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0617 21:45:18.714380503      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0617 21:45:18.714383207      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0617 21:45:18.714385943      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0617 21:45:18.714392256      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0617 21:45:18.714406958      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0617 21:45:18.714433167      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0617 21:45:18.714445313      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0617 21:45:18.714448408      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0617 21:45:18.714451188      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0617 21:45:18.714456314      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0617 21:45:18.714459058      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0617 21:45:18.714461683      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0617 21:45:18.714465738      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0617 21:45:18.716481157      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0617 21:45:18.733576899     104 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0617 21:45:18.739851741     104 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2023-06-17T21:45:18.739833775+00:00\", grpc_status:2}\n","output_type":"stream"},{"name":"stdout","text":"Running on TPU  \nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"REPLICAS:  8\nEpoch 1/15\n127/127 [==============================] - 501s 4s/step - loss: 0.1960 - val_loss: 0.1562\nEpoch 2/15\n127/127 [==============================] - 487s 4s/step - loss: 0.1490 - val_loss: 0.1279\nEpoch 3/15\n127/127 [==============================] - 488s 4s/step - loss: 0.1458 - val_loss: 0.1429\nEpoch 4/15\n127/127 [==============================] - 490s 4s/step - loss: 0.1479 - val_loss: 0.1184\nEpoch 5/15\n127/127 [==============================] - 487s 4s/step - loss: 0.1443 - val_loss: 0.1043\nEpoch 6/15\n127/127 [==============================] - 490s 4s/step - loss: 0.1425 - val_loss: 0.1105\nEpoch 7/15\n127/127 [==============================] - 491s 4s/step - loss: 0.1340 - val_loss: 0.1285\nEpoch 8/15\n127/127 [==============================] - 488s 4s/step - loss: 0.1310 - val_loss: 0.1290\nEpoch 9/15\n127/127 [==============================] - 488s 4s/step - loss: 0.1309 - val_loss: 0.1136\nEpoch 10/15\n127/127 [==============================] - 484s 4s/step - loss: 0.1346 - val_loss: 0.1057\nEpoch 11/15\n127/127 [==============================] - 488s 4s/step - loss: 0.1357 - val_loss: 0.1008\nEpoch 12/15\n127/127 [==============================] - 489s 4s/step - loss: 0.1359 - val_loss: 0.1106\nEpoch 13/15\n127/127 [==============================] - 491s 4s/step - loss: 0.1360 - val_loss: 0.1231\nEpoch 14/15\n127/127 [==============================] - 487s 4s/step - loss: 0.1349 - val_loss: 0.1120\nEpoch 15/15\n127/127 [==============================] - 488s 4s/step - loss: 0.1381 - val_loss: 0.1134\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\n\n# Define path\npath_to_test = '/kaggle/input/ussimandsegm/abdominal_US/abdominal_US/AUS/images/test'\n\n# Load and resize images from directory\ndef load_images_from_folder(folder):\n    images = []\n    for filename in os.listdir(folder):\n        img = cv2.imread(os.path.join(folder, filename))\n        if img is not None:\n            img_resized = cv2.resize(img, (464, 464)) # Resize image to expected dimensions\n            images.append(img_resized)\n    return images\n\n# Using the function to load and resize test images\nX_test = load_images_from_folder(path_to_test)\n\n# Convert list to numpy array\nX_test = np.array(X_test)\n\n# Normalize the test data like we did with train data\nX_test = X_test / 255.0\n\n# Use model to make predictions\npredictions = model.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-17T23:48:48.729294Z","iopub.execute_input":"2023-06-17T23:48:48.729684Z","iopub.status.idle":"2023-06-17T23:49:32.411978Z","shell.execute_reply.started":"2023-06-17T23:48:48.729656Z","shell.execute_reply":"2023-06-17T23:49:32.410797Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"10/10 [==============================] - 36s 4s/step\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}